{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1adfefde-5616-4292-8d4f-82de54212cf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\user\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\user\\anaconda3\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: optuna in c:\\users\\user\\anaconda3\\lib\\site-packages (4.2.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\user\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (1.15.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (23.2)\n",
      "Requirement already satisfied: sqlalchemy>=1.4.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (2.0.30)\n",
      "Requirement already satisfied: tqdm in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (4.66.4)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\user\\anaconda3\\lib\\site-packages (from optuna) (6.0.1)\n",
      "Requirement already satisfied: Mako in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.9)\n",
      "Requirement already satisfied: typing-extensions>=4.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.4.2->optuna) (3.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of dropbox: .* suffix can only be used with `==` or `!=` operators\n",
      "    stone (>=2.*)\n",
      "           ~~~~^\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost scikit-learn pandas joblib imbalanced-learn optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0226b6a6-713d-420a-be57-8de50e857dfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 35\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Apply SMOTE to Handle Class Imbalance\u001b[39;00m\n\u001b[0;32m     34\u001b[0m smote \u001b[38;5;241m=\u001b[39m SMOTE(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 35\u001b[0m X_train_balanced, y_train_balanced \u001b[38;5;241m=\u001b[39m smote\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Print Class Distribution After SMOTE\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTE applied - Training set balanced\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:208\u001b[0m, in \u001b[0;36mBaseSampler.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    187\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m    188\u001b[0m \n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m--> 208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit_resample(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\imblearn\\base.py:104\u001b[0m, in \u001b[0;36mSamplerMixin.fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_resample\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y):\n\u001b[0;32m     84\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Resample the dataset.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[0;32m     86\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;124;03m        The corresponding label of `X_resampled`.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     check_classification_targets(y)\n\u001b[0;32m    105\u001b[0m     arrays_transformer \u001b[38;5;241m=\u001b[39m ArraysTransformer(X, y)\n\u001b[0;32m    106\u001b[0m     X, y, binarize_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_X_y(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:221\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    213\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m ]:\n\u001b[1;32m--> 221\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Maybe you are trying to fit a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassifier, which expects discrete classes on a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mregression target with continuous values.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: continuous-multioutput. Maybe you are trying to fit a classifier, which expects discrete classes on a regression target with continuous values."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv(\"k8Dataset .csv\")\n",
    "\n",
    "# Drop unnecessary column (if present)\n",
    "if \"Slow Response Likelihood (%)\" in df.columns:\n",
    "    df = df.drop(columns=[\"Slow Response Likelihood (%)\"])\n",
    "\n",
    "# One-Hot Encode 'Event Type' (Categorical Column)\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "encoded_event_type = encoder.fit_transform(df[['Event Type']])\n",
    "encoded_event_df = pd.DataFrame(encoded_event_type, columns=[f\"Event_Type_{i}\" for i in range(encoded_event_type.shape[1])])\n",
    "\n",
    "# Merge Encoded Data and Drop Original Categorical Column\n",
    "df = df.drop(columns=['Event Type']).reset_index(drop=True)\n",
    "df = pd.concat([df, encoded_event_df], axis=1)\n",
    "\n",
    "# Define Features (X) and Target Variables (Predict All 6 Parameters)\n",
    "X = df.drop(columns=['Failure Type'])  # Features\n",
    "y = df[['CPU Usage (%)', 'Memory Usage (%)', 'Disk Usage (%)', 'Network Latency (ms)', 'Packet Loss (%)', 'Pod Eviction Risk (%)']]  # Predict all 6\n",
    "\n",
    "# Split Data into Training (80%) and Testing (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Apply SMOTE to Handle Class Imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Print Class Distribution After SMOTE\n",
    "print(\"SMOTE applied - Training set balanced\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f9d376-2552-4082-896b-ee47d0466fac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_balanced' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Perform GridSearchCV for best parameters\u001b[39;00m\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mxgb_model, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr2\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m grid_search\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Print best parameters\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgrid_search\u001b[38;5;241m.\u001b[39mbest_params_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_balanced' is not defined"
     ]
    }
   ],
   "source": [
    "# Define parameter grid for tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],  # Number of trees\n",
    "    'max_depth': [6, 8, 10],          # Depth of each tree\n",
    "    'learning_rate': [0.01, 0.05, 0.1],  # Learning rate\n",
    "    'gamma': [0, 0.1, 0.2],           # Regularization parameter\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]  # Feature selection\n",
    "}\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBRegressor(eval_metric=\"rmse\")  # Regression for continuous values\n",
    "\n",
    "# Perform GridSearchCV for best parameters\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='r2', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Train final model with best parameters\n",
    "best_xgb_model = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb88982a-fc90-40bb-8c57-d22ca33d2179",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train XGBoost with best parameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict on Test Set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train XGBoost with best parameters\n",
    "best_xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on Test Set\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Compute Error Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d34e36-6f1b-4b6e-ae62-0ddd69337587",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Train XGBoost with best parameters\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m best_xgb_model\u001b[38;5;241m.\u001b[39mfit(X_train_balanced, y_train_balanced)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Predict on Test Set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Train XGBoost with best parameters\n",
    "best_xgb_model.fit(X_train_balanced, y_train_balanced)\n",
    "\n",
    "# Predict on Test Set\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate Model Performance\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Compute Error Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4768397-6e6e-4e61-9fef-f34266ed1993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessing Complete (Features Split & Targets Scaled).\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define Features (X) and Target Variables (y)  \n",
    "X = df.drop(columns=['Failure Type'])  # Features  \n",
    "y = df[['CPU Usage (%)', 'Memory Usage (%)', 'Disk Usage (%)', 'Network Latency (ms)', 'Packet Loss (%)', 'Pod Eviction Risk (%)']]  # Target  \n",
    "\n",
    "# Split Data into Training (80%) and Testing (20%)  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize Target Variables Using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "y_train_scaled = scaler.fit_transform(y_train)\n",
    "y_test_scaled = scaler.transform(y_test)\n",
    "\n",
    "print(\"Data Preprocessing Complete (Features Split & Targets Scaled).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de5d8a04-440f-40f4-a311-3f90a1af5c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Training Completed & Predictions Generated.\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Train XGBoost for Multi-Target Regression\n",
    "xgb_model = xgb.XGBRegressor(n_estimators=200, max_depth=8, learning_rate=0.05)\n",
    "\n",
    "# Fit the model on training data\n",
    "xgb_model.fit(X_train, y_train_scaled)\n",
    "\n",
    "# Predict on Test Set\n",
    "y_pred_scaled = xgb_model.predict(X_test)\n",
    "\n",
    "# Convert Predictions Back to Original Scale\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "print(\"XGBoost Training Completed & Predictions Generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77ae39d-e3c0-4f6f-b997-14c12c5320f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 0.0009077075178813525\n",
      "Mean Squared Error (MSE): 6.32068463474448e-06\n",
      "R2 Score: 0.9997857642117203\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Compute Error Metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce5624e5-a883-4cbb-aafb-f252fcb66da8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall XGBoost Model Accuracy: 99.98%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Compute overall model accuracy for predicting all 6 parameters\n",
    "overall_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Overall XGBoost Model Accuracy: {overall_r2_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a31affcc-7f40-4fc3-8b41-be4f4631eac5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_xgb_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Make Predictions on Test Data\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m best_xgb_model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Compute Overall Accuracy\u001b[39;00m\n\u001b[0;32m      7\u001b[0m overall_r2_score \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'best_xgb_model' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Make Predictions on Test Data\n",
    "y_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Compute Overall Accuracy\n",
    "overall_r2_score = r2_score(y_test, y_pred)\n",
    "print(f\"✅ **Overall Model Accuracy on Test Data: {overall_r2_score * 100:.2f}%**\")\n",
    "\n",
    "# Show a Sample Test Prediction\n",
    "sample_input = X_test.iloc[:1]  # Pick one sample row\n",
    "sample_prediction = best_xgb_model.predict(sample_input)\n",
    "\n",
    "print(\"\\n📌 Sample Test Data Input:\\n\", sample_input)\n",
    "print(\"\\n🎯 Predicted Values:\\n\", sample_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7901196d-b066-4c69-906e-4e0a14abc79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Trained Successfully!\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Define and Train XGBoost Model\n",
    "best_xgb_model = xgb.XGBRegressor(n_estimators=200, max_depth=8, learning_rate=0.05)\n",
    "\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"✅ Model Trained Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60f71b5e-7760-418d-b261-3c09a8d4e6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model saved successfully as 'xgboost_multitarget_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(best_xgb_model, \"xgboost_multitarget_model.pkl\")\n",
    "\n",
    "print(\"✅ Model saved successfully as 'xgboost_multitarget_model.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ab2ce15-7eb6-4e26-8474-3310d2d8e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Model Accuracy on Test Data: 99.98%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "loaded_model = joblib.load(\"xgboost_multitarget_model.pkl\")\n",
    "\n",
    "# Test Predictions\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Compute Accuracy\n",
    "from sklearn.metrics import r2_score\n",
    "overall_r2_score = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"🎯 Model Accuracy on Test Data: {overall_r2_score * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e352c48f-9f4b-4743-b7fc-9ae488a5b9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ **Overall Model Accuracy on Test Data: 99.98%**\n",
      "\n",
      "📌 Sample Test Data Input:\n",
      "       CPU Usage (%)  Memory Usage (%)  Disk Usage (%)  Network Latency (ms)  \\\n",
      "6252            1.0          0.561822        0.663669              0.285373   \n",
      "\n",
      "      Packet Loss (%)  Error Logs Count  Pod Eviction Risk (%)  Event_Type_0  \\\n",
      "6252          0.51974               0.2                    0.0           0.0   \n",
      "\n",
      "      Event_Type_1  Event_Type_2  \n",
      "6252           1.0           0.0  \n",
      "\n",
      "🎯 Predicted Values:\n",
      " [[9.8441589e-01 5.6121349e-01 6.6250628e-01 2.8536391e-01 5.1865375e-01\n",
      "  1.4142146e-05]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Load the saved model\n",
    "import joblib\n",
    "loaded_model = joblib.load(\"xgboost_multitarget_model.pkl\")\n",
    "\n",
    "# Make Predictions on Test Data\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "\n",
    "# Compute Overall Accuracy\n",
    "overall_r2_score = r2_score(y_test, y_pred)\n",
    "print(f\"✅ **Overall Model Accuracy on Test Data: {overall_r2_score * 100:.2f}%**\")\n",
    "\n",
    "# Show a Sample Test Prediction\n",
    "sample_input = X_test.iloc[:1]  # Pick one sample row\n",
    "sample_prediction = loaded_model.predict(sample_input)\n",
    "\n",
    "print(\"\\n📌 Sample Test Data Input:\\n\", sample_input)\n",
    "print(\"\\n🎯 Predicted Values:\\n\", sample_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "076adac2-f152-4d77-abae-cc6470a25a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\users\\user\\anaconda3\\lib\\site-packages (3.0.3)\n",
      "Requirement already satisfied: Werkzeug>=3.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask) (3.0.3)\n",
      "Requirement already satisfied: Jinja2>=3.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask) (3.1.4)\n",
      "Requirement already satisfied: itsdangerous>=2.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask) (2.2.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask) (8.1.7)\n",
      "Requirement already satisfied: blinker>=1.6.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from flask) (1.6.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from click>=8.1.3->flask) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from Jinja2>=3.1.2->flask) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Error parsing dependencies of dropbox: .* suffix can only be used with `==` or `!=` operators\n",
      "    stone (>=2.*)\n",
      "           ~~~~^\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install flask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "112b7f69-7973-4dc3-ae2f-91e75cb220b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3585: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Trained Model\n",
    "model = joblib.load(\"xgboost_multitarget_model.pkl\")\n",
    "\n",
    "# Initialize Flask App\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get JSON data from request\n",
    "    data = request.get_json()\n",
    "\n",
    "    # Convert JSON to DataFrame\n",
    "    input_data = pd.DataFrame([data])\n",
    "\n",
    "    # Make Prediction\n",
    "    prediction = model.predict(input_data)\n",
    "\n",
    "    # Convert prediction to JSON format\n",
    "    response = {\n",
    "        \"CPU Usage (%)\": float(prediction[0][0]),\n",
    "        \"Memory Usage (%)\": float(prediction[0][1]),\n",
    "        \"Disk Usage (%)\": float(prediction[0][2]),\n",
    "        \"Network Latency (ms)\": float(prediction[0][3]),\n",
    "        \"Packet Loss (%)\": float(prediction[0][4]),\n",
    "        \"Pod Eviction Risk (%)\": float(prediction[0][5]),\n",
    "    }\n",
    "\n",
    "    return jsonify(response)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "740424e1-caf9-43a3-ab24-f0c0fae00a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📌 Sample Testing Data (Input):\n",
      "      CPU Usage (%)  Memory Usage (%)  Disk Usage (%)  Network Latency (ms)  \\\n",
      "4343       0.705022          0.572458        0.465281              0.789997   \n",
      "1794       0.542639          0.830732        0.233664              0.019865   \n",
      "708        0.083614          0.454354        0.292465              0.231112   \n",
      "3383       0.705397          0.732097        0.183200              0.143427   \n",
      "4534       0.648492          0.442284        0.505883              0.631654   \n",
      "\n",
      "      Packet Loss (%)  Error Logs Count  Pod Eviction Risk (%)  Event_Type_0  \\\n",
      "4343         0.380551               0.1               0.000000           0.0   \n",
      "1794         0.432600               0.2               0.843415           0.0   \n",
      "708          0.304388               0.2               0.000000           0.0   \n",
      "3383         0.347588               0.3               0.000000           0.0   \n",
      "4534         0.514232               0.2               0.000000           0.0   \n",
      "\n",
      "      Event_Type_1  Event_Type_2  \n",
      "4343           0.0           1.0  \n",
      "1794           1.0           0.0  \n",
      "708            1.0           0.0  \n",
      "3383           1.0           0.0  \n",
      "4534           1.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Select 5 random rows from the test set\n",
    "sample_test_data = X_test.sample(5, random_state=42)\n",
    "\n",
    "# Print sample test data\n",
    "print(\"\\n📌 Sample Testing Data (Input):\")\n",
    "print(sample_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8cc42707-f026-497a-a87f-4453c0c9019e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎯 Predictions for Sample Testing Data:\n",
      "\n",
      "🔹 Test Sample 1:\n",
      "   - CPU Usage (%): 0.71\n",
      "   - Memory Usage (%): 0.57\n",
      "   - Disk Usage (%): 0.47\n",
      "   - Network Latency (ms): 0.79\n",
      "   - Packet Loss (%): 0.38\n",
      "   - Pod Eviction Risk (%): 0.00\n",
      "\n",
      "🔹 Test Sample 2:\n",
      "   - CPU Usage (%): 0.54\n",
      "   - Memory Usage (%): 0.83\n",
      "   - Disk Usage (%): 0.23\n",
      "   - Network Latency (ms): 0.02\n",
      "   - Packet Loss (%): 0.43\n",
      "   - Pod Eviction Risk (%): 0.84\n",
      "\n",
      "🔹 Test Sample 3:\n",
      "   - CPU Usage (%): 0.09\n",
      "   - Memory Usage (%): 0.45\n",
      "   - Disk Usage (%): 0.29\n",
      "   - Network Latency (ms): 0.23\n",
      "   - Packet Loss (%): 0.30\n",
      "   - Pod Eviction Risk (%): 0.00\n",
      "\n",
      "🔹 Test Sample 4:\n",
      "   - CPU Usage (%): 0.71\n",
      "   - Memory Usage (%): 0.73\n",
      "   - Disk Usage (%): 0.18\n",
      "   - Network Latency (ms): 0.14\n",
      "   - Packet Loss (%): 0.35\n",
      "   - Pod Eviction Risk (%): 0.00\n",
      "\n",
      "🔹 Test Sample 5:\n",
      "   - CPU Usage (%): 0.65\n",
      "   - Memory Usage (%): 0.44\n",
      "   - Disk Usage (%): 0.51\n",
      "   - Network Latency (ms): 0.63\n",
      "   - Packet Loss (%): 0.51\n",
      "   - Pod Eviction Risk (%): 0.00\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved XGBoost model\n",
    "model = joblib.load(\"xgboost_multitarget_model.pkl\")\n",
    "\n",
    "# Predict on sample test data\n",
    "sample_predictions = model.predict(sample_test_data)\n",
    "\n",
    "# Print Predictions\n",
    "print(\"\\n🎯 Predictions for Sample Testing Data:\")\n",
    "for i, row in enumerate(sample_predictions):\n",
    "    print(f\"\\n🔹 Test Sample {i+1}:\")\n",
    "    print(f\"   - CPU Usage (%): {row[0]:.2f}\")\n",
    "    print(f\"   - Memory Usage (%): {row[1]:.2f}\")\n",
    "    print(f\"   - Disk Usage (%): {row[2]:.2f}\")\n",
    "    print(f\"   - Network Latency (ms): {row[3]:.2f}\")\n",
    "    print(f\"   - Packet Loss (%): {row[4]:.2f}\")\n",
    "    print(f\"   - Pod Eviction Risk (%): {row[5]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ee32c17d-9450-461f-9d09-b2bc9cafdbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ **Overall Model Accuracy on Test Data: 99.98%**\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Predict on full test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute Overall Accuracy\n",
    "overall_r2_score = r2_score(y_test, y_pred)\n",
    "print(f\"\\n✅ **Overall Model Accuracy on Test Data: {overall_r2_score * 100:.2f}%**\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d8e4ad74-ac0c-49c0-bfec-00abb44de86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Model Accuracy: 99.70%\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       606\n",
      "           1       0.99      1.00      1.00       666\n",
      "           2       1.00      0.99      1.00       250\n",
      "           3       0.99      1.00      0.99       161\n",
      "           4       1.00      0.99      1.00       266\n",
      "           5       1.00      0.98      0.99        51\n",
      "\n",
      "    accuracy                           1.00      2000\n",
      "   macro avg       1.00      0.99      1.00      2000\n",
      "weighted avg       1.00      1.00      1.00      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Make Predictions on Test Data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert predictions & actual values to class labels (if needed)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Compute Accuracy\n",
    "overall_accuracy = accuracy_score(y_test_labels, y_pred_labels) * 100\n",
    "\n",
    "# Generate Classification Report\n",
    "report = classification_report(y_test_labels, y_pred_labels, digits=2)\n",
    "\n",
    "# Print Model Accuracy & Report in Desired Format\n",
    "print(f\"XGBoost Model Accuracy: {overall_accuracy:.2f}%\\n\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd34a136-b6fe-4092-9de6-02f3d8265d8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
